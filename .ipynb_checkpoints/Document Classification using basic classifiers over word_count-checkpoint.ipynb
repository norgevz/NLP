{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, glob, codecs\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "dirs = glob.glob('data/20news-bydate/20news-bydate-train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/20news-bydate/20news-bydate-train/alt.atheism 480\n",
      "data/20news-bydate/20news-bydate-train/comp.graphics 584\n",
      "data/20news-bydate/20news-bydate-train/comp.os.ms-windows.misc 591\n",
      "data/20news-bydate/20news-bydate-train/comp.sys.ibm.pc.hardware 590\n",
      "data/20news-bydate/20news-bydate-train/comp.sys.mac.hardware 578\n",
      "data/20news-bydate/20news-bydate-train/comp.windows.x 593\n",
      "data/20news-bydate/20news-bydate-train/misc.forsale 585\n",
      "data/20news-bydate/20news-bydate-train/rec.autos 594\n",
      "data/20news-bydate/20news-bydate-train/rec.motorcycles 598\n",
      "data/20news-bydate/20news-bydate-train/rec.sport.baseball 597\n",
      "data/20news-bydate/20news-bydate-train/rec.sport.hockey 600\n",
      "data/20news-bydate/20news-bydate-train/sci.crypt 595\n",
      "data/20news-bydate/20news-bydate-train/sci.electronics 591\n",
      "data/20news-bydate/20news-bydate-train/sci.med 594\n",
      "data/20news-bydate/20news-bydate-train/sci.space 593\n",
      "data/20news-bydate/20news-bydate-train/soc.religion.christian 599\n",
      "data/20news-bydate/20news-bydate-train/talk.politics.guns 546\n",
      "data/20news-bydate/20news-bydate-train/talk.politics.mideast 564\n",
      "data/20news-bydate/20news-bydate-train/talk.politics.misc 465\n",
      "data/20news-bydate/20news-bydate-train/talk.religion.misc 377\n"
     ]
    }
   ],
   "source": [
    "train_set = []\n",
    "train_labels = []\n",
    "total_counts = collections.Counter()\n",
    "\n",
    "for directory in dirs:\n",
    "    filenames = glob.glob(directory + '/*')\n",
    "    for filename in filenames:\n",
    "        with codecs.open(filename, 'r', 'latin1') as f:\n",
    "            lines = f.readlines()\n",
    "            lines_proc = [y for x in lines for y in x.strip().lower().translate(translator).split()]\n",
    "            count = collections.Counter(lines_proc)\n",
    "            total_counts += count\n",
    "            train_set.append(count)\n",
    "            train_labels.append(os.path.basename(os.path.dirname(filename)))\n",
    "    print(directory + \" \" + str(len(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_counts = {w : c for w , c in total_counts.items() if c > 9}\n",
    "vocab = { w : i for i,w in enumerate(sorted(vocab_counts))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_set), len(vocab)))\n",
    "for iDoc, doc in enumerate(train_set):\n",
    "    for w,c in doc.items():\n",
    "        if w in vocab:\n",
    "            X[iDoc, vocab[w]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = sorted(collections.Counter(train_labels).keys())\n",
    "labels_dict = {l : i for i,l in enumerate(labels_array)}\n",
    "y = np.array([labels_dict[x] for x in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 20192)\n",
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x20192 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1667404 stored elements in LInked List format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90825525897118609"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = MultinomialNB()\n",
    "model.fit(X , y)\n",
    "model.score(X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82923811207353726"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = BernoulliNB()\n",
    "model.fit(X , y)\n",
    "model.score(X , y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/20news-bydate/20news-bydate-test/alt.atheism 319\n",
      "data/20news-bydate/20news-bydate-test/comp.graphics 389\n",
      "data/20news-bydate/20news-bydate-test/comp.os.ms-windows.misc 394\n",
      "data/20news-bydate/20news-bydate-test/comp.sys.ibm.pc.hardware 392\n",
      "data/20news-bydate/20news-bydate-test/comp.sys.mac.hardware 385\n",
      "data/20news-bydate/20news-bydate-test/comp.windows.x 395\n",
      "data/20news-bydate/20news-bydate-test/misc.forsale 390\n",
      "data/20news-bydate/20news-bydate-test/rec.autos 396\n",
      "data/20news-bydate/20news-bydate-test/rec.motorcycles 398\n",
      "data/20news-bydate/20news-bydate-test/rec.sport.baseball 397\n",
      "data/20news-bydate/20news-bydate-test/rec.sport.hockey 399\n",
      "data/20news-bydate/20news-bydate-test/sci.crypt 396\n",
      "data/20news-bydate/20news-bydate-test/sci.electronics 393\n",
      "data/20news-bydate/20news-bydate-test/sci.med 396\n",
      "data/20news-bydate/20news-bydate-test/sci.space 394\n",
      "data/20news-bydate/20news-bydate-test/soc.religion.christian 398\n",
      "data/20news-bydate/20news-bydate-test/talk.politics.guns 364\n",
      "data/20news-bydate/20news-bydate-test/talk.politics.mideast 376\n",
      "data/20news-bydate/20news-bydate-test/talk.politics.misc 310\n",
      "data/20news-bydate/20news-bydate-test/talk.religion.misc 251\n"
     ]
    }
   ],
   "source": [
    "dirs = glob.glob('data/20news-bydate/20news-bydate-test/*')\n",
    "\n",
    "test_set = []\n",
    "test_labels = []\n",
    "test_total_counts = collections.Counter()\n",
    "\n",
    "for directory in dirs:\n",
    "    filenames = glob.glob(directory + '/*')\n",
    "    for filename in filenames:\n",
    "        with codecs.open(filename, 'r', 'latin1') as f:\n",
    "            lines = f.readlines()\n",
    "            lines_proc = [y for x in lines for y in x.strip().lower().translate(translator).split()]\n",
    "            count = collections.Counter(lines_proc)\n",
    "            test_total_counts += count\n",
    "            test_set.append(count)\n",
    "            test_labels.append(os.path.basename(os.path.dirname(filename)))\n",
    "    print(directory + \" \" + str(len(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_set), len(vocab)))\n",
    "for iDoc, doc in enumerate(test_set):\n",
    "    for w,c in doc.items():\n",
    "        if w in vocab:\n",
    "            X_test[iDoc, vocab[w]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([labels_dict[x] for x in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94715878916622409"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = MultinomialNB()\n",
    "model.fit(X_test , y_test)\n",
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82952734997344668"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = BernoulliNB()\n",
    "model.fit(X_test , y_test)\n",
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880509824747743"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler( with_mean=False ).fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "model  = MultinomialNB()\n",
    "model.fit(X_test , y_test)\n",
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78850238980350507"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "model  = MultinomialNB()\n",
    "model.fit(X , y)\n",
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "#     \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators = 18),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classifiers = len(dict_classifiers.keys())\n",
    "\n",
    "def batch_classify(X_train, Y_train, X_test, Y_test, verbose = True):\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,4)), columns = ['classifier', 'train_score', 'test_score', 'training_time'])\n",
    "    count = 0\n",
    "    for key, classifier in dict_classifiers.items():\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.clock()\n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'train_score'] = train_score\n",
    "        df_results.loc[count,'test_score'] = test_score\n",
    "        df_results.loc[count,'training_time'] = t_diff\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=key, f=t_diff))\n",
    "        count+=1\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = batch_classify(X, y, X_test, y_test)\n",
    "display(df_results.sort_values(by='test_score', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
