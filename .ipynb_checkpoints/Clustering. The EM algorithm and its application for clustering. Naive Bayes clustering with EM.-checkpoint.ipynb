{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very naive and straightforward text categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import collections\n",
    "import glob\n",
    "import codecs\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "translator = str.maketrans(\"\",\"\", string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helicopters fli'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"helicopters flying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    return [ stemmer.stem(x) for x in nltk.tokenize.word_tokenize(s.lower().translate(translator)) if not x in stopwords ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for directory in glob.glob('data/20news-bydate/20news-bydate-train/*') for x in glob.glob(directory + '/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(input='filename', encoding='latin1', min_df=10)\n",
    "X = cv.fit_transform([x for directory in glob.glob('data/20news-bydate/20news-bydate-train/*') for x in glob.glob(directory + '/*')])\n",
    "cv.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(input='filename', encoding='latin1', min_df=10, max_df=200, ngram_range=(1, 2), tokenizer=my_tokenizer)\n",
    "X = tfv.fit_transform([x for directory in glob.glob('20news-bydate-train/*') for x in glob.glob(directory + '/*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = sorted(list(set([directory.split('/')[-1] for directory in glob.glob('20news-bydate-train/*')])))\n",
    "labels_dict = {l: i for i, l in enumerate(labels_array)}\n",
    "y = np.array([labels_dict[directory.split('/')[-1]] for directory in glob.glob('20news-bydate-train/*') for x in glob.glob(directory + '/*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = tfv.transform([x for directory in glob.glob('20news-bydate-test/*') for x in glob.glob(directory + '/*')])\n",
    "y_test = np.array([labels_dict[x.split('/')[1]] for x in [directory for directory in glob.glob('20news-bydate-test/*') for x in glob.glob(directory + '/*')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 10483), (11314,), (7532, 10483), (7532,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('god', -6.2189046232034997),\n",
       " ('atheist', -6.3988392865917323),\n",
       " ('moral', -6.4395034832551241),\n",
       " ('islam', -6.4580124877455729),\n",
       " ('keith', -6.491187027997869),\n",
       " ('write', -6.7550487363271898),\n",
       " ('one', -6.8238868903327816),\n",
       " ('peopl', -6.8291634263994982),\n",
       " ('say', -6.8784324388447491),\n",
       " ('atheism', -6.9563495174527779),\n",
       " ('articl', -6.9797632844082873),\n",
       " ('dont', -6.9995806838319048),\n",
       " ('religion', -7.0279409120691465),\n",
       " ('think', -7.0299183749454137),\n",
       " ('would', -7.0827037177702472),\n",
       " ('jon', -7.0853506268168882),\n",
       " ('schneider', -7.1022536790955177),\n",
       " ('believ', -7.1170541127290292),\n",
       " ('thing', -7.1721647529960961),\n",
       " ('object', -7.1743589046410321)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "vocab_array = tfv.get_feature_names()\n",
    "model.coef_.shape\n",
    "[(vocab_array[y[0]], y[1]) for y in sorted([(i,x) for i, x in enumerate(model.coef_[0])], key=lambda x: np.abs(x[1]))[:20] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Train set: 0.92514\tTest set: 0.81784\n",
      "BernoulliNB\n",
      "Train set: 0.84285\tTest set: 0.69331\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, name=None):\n",
    "    if not name is None:\n",
    "        print(name)\n",
    "    model.fit(X, y)\n",
    "    print(\"Train set: %.5f\\tTest set: %.5f\" % (model.score(X, y), model.score(X_test, y_test)) )\n",
    "\n",
    "test_model(MultinomialNB(), 'MultinomialNB')\n",
    "test_model(BernoulliNB(), 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Train set: 0.99788\tTest set: 0.82900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "test_model(LinearSVC(), 'LinearSVC')\n",
    "# test_model(SVC(kernel='rbf'), 'SVC RBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegr\n",
      "Train set: 0.95395\tTest set: 0.82209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "test_model(LogisticRegression(), 'LogRegr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
